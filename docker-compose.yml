services:
  llm:
    build: ./llm-engine
    container_name: "llm"
    environment:
      - OLLAMA_HOST=0.0.0.0
    networks:
      - default-net
    volumes:
      - './llm-engine/data:/data'
    ports:
      - 11434:11434
  
  backend:
    build: ./backend
    container_name: "backend"
    networks:
      - default-net
    volumes:
      - './backend/data:/chdb_data'
      - './backend/src:/app/api'
    ports:
      - 8000:8000

networks:
  default-net:
    driver: bridge
    ipam:
      config:
        - subnet: 192.190.128.0/24
